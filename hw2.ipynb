{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01ade2a3",
   "metadata": {},
   "source": [
    "## ДЗ 2\n",
    "\n",
    "### Задание 1.\n",
    "Задание: обучите три классификатора:\n",
    "\n",
    "1) на токенах с высокой частотой\n",
    "\n",
    "2) на токенах со средней частотой\n",
    "\n",
    "3) на токенах с низкой частотой\n",
    "\n",
    "Сравните полученные результаты, оцените какие токены наиболее важные для классификации.\n",
    "#### Сделано\n",
    "\n",
    "### Задание 2.\n",
    "найти фичи с наибольшей значимостью, и вывести их\n",
    "#### Сделано\n",
    "\n",
    "### Задание 3.\n",
    "1) сравнить count/tf-idf/hashing векторайзеры/полносвязанную сетку (построить classification_report)\n",
    "#### Сделано кроме полносвязной сетки\n",
    "\n",
    "2) подобрать оптимальный размер для hashing векторайзера\n",
    "#### Сделано\n",
    "\n",
    "3) убедиться что для сетки нет переобучения\n",
    "#### Не успела, доделаю на выходных до 24.04\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2183ed80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "176df0cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Stuning even for the non-gamer: This sound tra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>The best soundtrack ever to anything.: I'm rea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Amazing!: This soundtrack is my favorite music...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Excellent Soundtrack: I truly like this soundt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2</td>\n",
       "      <td>A revelation of life in small town America in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>2</td>\n",
       "      <td>Great biography of a very interesting journali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1</td>\n",
       "      <td>Interesting Subject; Poor Presentation: You'd ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1</td>\n",
       "      <td>Don't buy: The box looked used and it is obvio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>2</td>\n",
       "      <td>Beautiful Pen and Fast Delivery.: The pen was ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     category                                               text\n",
       "0           2  Stuning even for the non-gamer: This sound tra...\n",
       "1           2  The best soundtrack ever to anything.: I'm rea...\n",
       "2           2  Amazing!: This soundtrack is my favorite music...\n",
       "3           2  Excellent Soundtrack: I truly like this soundt...\n",
       "4           2  Remember, Pull Your Jaw Off The Floor After He...\n",
       "...       ...                                                ...\n",
       "9995        2  A revelation of life in small town America in ...\n",
       "9996        2  Great biography of a very interesting journali...\n",
       "9997        1  Interesting Subject; Poor Presentation: You'd ...\n",
       "9998        1  Don't buy: The box looked used and it is obvio...\n",
       "9999        2  Beautiful Pen and Fast Delivery.: The pen was ...\n",
       "\n",
       "[10000 rows x 2 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('hw2_corpus.txt', 'r') as f:\n",
    "    df = pd.DataFrame({'category': t[0], 'text': t[1]} for t in (l.split(' ', 1) for l in f.readlines()))\n",
    "df['category'] = df['category'].apply(lambda t: re.search(r'\\d+', t).group())\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3d7bc0b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>text_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Stuning even for the non-gamer: This sound tra...</td>\n",
       "      <td>[Stuning, even, non-gamer, This, sound, track,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>The best soundtrack ever to anything.: I'm rea...</td>\n",
       "      <td>[The, best, soundtrack, ever, anything, I, 'm,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Amazing!: This soundtrack is my favorite music...</td>\n",
       "      <td>[Amazing, This, soundtrack, favorite, music, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Excellent Soundtrack: I truly like this soundt...</td>\n",
       "      <td>[Excellent, Soundtrack, I, truly, like, soundt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
       "      <td>[Remember, Pull, Your, Jaw, Off, The, Floor, A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2</td>\n",
       "      <td>A revelation of life in small town America in ...</td>\n",
       "      <td>[A, revelation, life, small, town, America, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>2</td>\n",
       "      <td>Great biography of a very interesting journali...</td>\n",
       "      <td>[Great, biography, interesting, journalist, Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1</td>\n",
       "      <td>Interesting Subject; Poor Presentation: You'd ...</td>\n",
       "      <td>[Interesting, Subject, Poor, Presentation, You...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1</td>\n",
       "      <td>Don't buy: The box looked used and it is obvio...</td>\n",
       "      <td>[Do, n't, buy, The, box, looked, used, obvious...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>2</td>\n",
       "      <td>Beautiful Pen and Fast Delivery.: The pen was ...</td>\n",
       "      <td>[Beautiful, Pen, Fast, Delivery, The, pen, shi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     category                                               text  \\\n",
       "0           2  Stuning even for the non-gamer: This sound tra...   \n",
       "1           2  The best soundtrack ever to anything.: I'm rea...   \n",
       "2           2  Amazing!: This soundtrack is my favorite music...   \n",
       "3           2  Excellent Soundtrack: I truly like this soundt...   \n",
       "4           2  Remember, Pull Your Jaw Off The Floor After He...   \n",
       "...       ...                                                ...   \n",
       "9995        2  A revelation of life in small town America in ...   \n",
       "9996        2  Great biography of a very interesting journali...   \n",
       "9997        1  Interesting Subject; Poor Presentation: You'd ...   \n",
       "9998        1  Don't buy: The box looked used and it is obvio...   \n",
       "9999        2  Beautiful Pen and Fast Delivery.: The pen was ...   \n",
       "\n",
       "                                            text_tokens  \n",
       "0     [Stuning, even, non-gamer, This, sound, track,...  \n",
       "1     [The, best, soundtrack, ever, anything, I, 'm,...  \n",
       "2     [Amazing, This, soundtrack, favorite, music, t...  \n",
       "3     [Excellent, Soundtrack, I, truly, like, soundt...  \n",
       "4     [Remember, Pull, Your, Jaw, Off, The, Floor, A...  \n",
       "...                                                 ...  \n",
       "9995  [A, revelation, life, small, town, America, ea...  \n",
       "9996  [Great, biography, interesting, journalist, Th...  \n",
       "9997  [Interesting, Subject, Poor, Presentation, You...  \n",
       "9998  [Do, n't, buy, The, box, looked, used, obvious...  \n",
       "9999  [Beautiful, Pen, Fast, Delivery, The, pen, shi...  \n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from string import punctuation\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "noise = set(stopwords + list(punctuation))\n",
    "df['text_tokens'] = df['text'].apply(lambda t: [w for w in nltk.word_tokenize(t) if w not in noise])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "3c6e2b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>text</th>\n",
       "      <th>text_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Stuning even for the non-gamer: This sound tra...</td>\n",
       "      <td>[Stuning, even, non-gamer, This, sound, track,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>The best soundtrack ever to anything.: I'm rea...</td>\n",
       "      <td>[The, best, soundtrack, ever, anything, I, 'm,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Amazing!: This soundtrack is my favorite music...</td>\n",
       "      <td>[Amazing, This, soundtrack, favorite, music, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Excellent Soundtrack: I truly like this soundt...</td>\n",
       "      <td>[Excellent, Soundtrack, I, truly, like, soundt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>Remember, Pull Your Jaw Off The Floor After He...</td>\n",
       "      <td>[Remember, Pull, Your, Jaw, Off, The, Floor, A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>2</td>\n",
       "      <td>A revelation of life in small town America in ...</td>\n",
       "      <td>[A, revelation, life, small, town, America, ea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>2</td>\n",
       "      <td>Great biography of a very interesting journali...</td>\n",
       "      <td>[Great, biography, interesting, journalist, Th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>1</td>\n",
       "      <td>Interesting Subject; Poor Presentation: You'd ...</td>\n",
       "      <td>[Interesting, Subject, Poor, Presentation, You...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>1</td>\n",
       "      <td>Don't buy: The box looked used and it is obvio...</td>\n",
       "      <td>[Do, n't, buy, The, box, looked, used, obvious...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>2</td>\n",
       "      <td>Beautiful Pen and Fast Delivery.: The pen was ...</td>\n",
       "      <td>[Beautiful, Pen, Fast, Delivery, The, pen, shi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     category                                               text  \\\n",
       "0           2  Stuning even for the non-gamer: This sound tra...   \n",
       "1           2  The best soundtrack ever to anything.: I'm rea...   \n",
       "2           2  Amazing!: This soundtrack is my favorite music...   \n",
       "3           2  Excellent Soundtrack: I truly like this soundt...   \n",
       "4           2  Remember, Pull Your Jaw Off The Floor After He...   \n",
       "...       ...                                                ...   \n",
       "9995        2  A revelation of life in small town America in ...   \n",
       "9996        2  Great biography of a very interesting journali...   \n",
       "9997        1  Interesting Subject; Poor Presentation: You'd ...   \n",
       "9998        1  Don't buy: The box looked used and it is obvio...   \n",
       "9999        2  Beautiful Pen and Fast Delivery.: The pen was ...   \n",
       "\n",
       "                                            text_tokens  \n",
       "0     [Stuning, even, non-gamer, This, sound, track,...  \n",
       "1     [The, best, soundtrack, ever, anything, I, 'm,...  \n",
       "2     [Amazing, This, soundtrack, favorite, music, t...  \n",
       "3     [Excellent, Soundtrack, I, truly, like, soundt...  \n",
       "4     [Remember, Pull, Your, Jaw, Off, The, Floor, A...  \n",
       "...                                                 ...  \n",
       "9995  [A, revelation, life, small, town, America, ea...  \n",
       "9996  [Great, biography, interesting, journalist, Th...  \n",
       "9997  [Interesting, Subject, Poor, Presentation, You...  \n",
       "9998  [Do, n't, buy, The, box, looked, used, obvious...  \n",
       "9999  [Beautiful, Pen, Fast, Delivery, The, pen, shi...  \n",
       "\n",
       "[10000 rows x 3 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = nltk.stem.wordnet.WordNetLemmatizer()\n",
    "df['text_tokens'] = df['text_tokens'].apply(lambda l: [ lemmatizer.lemmatize(t) for t in l ])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bc3d9f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "corpus = [ t for ts in df.text_tokens for t in ts ]\n",
    "freq_dicts = list(tp[0] for tp in sorted(Counter(corpus).items(), key=lambda x: -x[1]))\n",
    "\n",
    "freq_dicts = { \n",
    "    'all': set(freq_dicts),\n",
    "    '<5%': set(freq_dicts[:len(freq_dicts)//20]), \n",
    "    '5-20%': set(freq_dicts[len(freq_dicts)//20 : len(freq_dicts)//5]),  \n",
    "    '>20%': set(freq_dicts[len(freq_dicts)//5:]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "15c2c8e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CountVectorizer:\n",
      "Символы частоты: all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наиболее значимые положительные: \n",
      "excellent : 2.419\n",
      "perfect : 1.930\n",
      "amazing : 1.493\n",
      "awesome : 1.478\n",
      "government : 1.408\n",
      "wonderful : 1.343\n",
      "works : 1.320\n",
      "love : 1.286\n",
      "emotion : 1.245\n",
      "favorite : 1.224\n",
      "Наиболее значимые отрицательные: \n",
      "boring : -2.423\n",
      "poor : -2.387\n",
      "waste : -2.072\n",
      "worst : -2.027\n",
      "disappointing : -1.814\n",
      "disappointed : -1.764\n",
      "not : -1.584\n",
      "disappointment : -1.499\n",
      "awful : -1.395\n",
      "horrible : -1.339\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.86      0.86      1045\n",
      "           2       0.85      0.86      0.85       955\n",
      "\n",
      "    accuracy                           0.86      2000\n",
      "   macro avg       0.86      0.86      0.86      2000\n",
      "weighted avg       0.86      0.86      0.86      2000\n",
      "\n",
      "Символы частоты: <5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наиболее значимые положительные: \n",
      "excellent : 2.336\n",
      "intense : 2.083\n",
      "perfect : 1.982\n",
      "epic : 1.778\n",
      "amazing : 1.714\n",
      "fantastic : 1.634\n",
      "helped : 1.617\n",
      "emotion : 1.556\n",
      "provides : 1.503\n",
      "flow : 1.498\n",
      "Наиболее значимые отрицательные: \n",
      "boring : -2.878\n",
      "worst : -2.407\n",
      "poor : -2.406\n",
      "disappointment : -2.230\n",
      "disappointing : -2.070\n",
      "waste : -2.004\n",
      "beware : -1.831\n",
      "misleading : -1.769\n",
      "terrible : -1.736\n",
      "ridiculous : -1.716\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.83      0.83      0.83      1044\n",
      "           2       0.81      0.82      0.82       956\n",
      "\n",
      "    accuracy                           0.82      2000\n",
      "   macro avg       0.82      0.82      0.82      2000\n",
      "weighted avg       0.82      0.82      0.82      2000\n",
      "\n",
      "Символы частоты: 5-20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наиболее значимые положительные: \n",
      "awsome : 1.881\n",
      "outstanding : 1.406\n",
      "amazing : 1.400\n",
      "clan : 1.364\n",
      "ease : 1.360\n",
      "securely : 1.350\n",
      "ya : 1.349\n",
      "medical : 1.346\n",
      "enjoys : 1.337\n",
      "row : 1.329\n",
      "Наиболее значимые отрицательные: \n",
      "awful : -1.970\n",
      "dont : -1.859\n",
      "wrong : -1.814\n",
      "annoyed : -1.799\n",
      "junk : -1.707\n",
      "redeeming : -1.643\n",
      "missing : -1.623\n",
      "essentially : -1.610\n",
      "none : -1.586\n",
      "rambling : -1.557\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.70      0.68       978\n",
      "           2       0.70      0.66      0.68      1022\n",
      "\n",
      "    accuracy                           0.68      2000\n",
      "   macro avg       0.68      0.68      0.68      2000\n",
      "weighted avg       0.68      0.68      0.68      2000\n",
      "\n",
      "Символы частоты: >20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наиболее значимые положительные: \n",
      "heart : 1.693\n",
      "excelent : 1.105\n",
      "must : 1.097\n",
      "highly : 1.095\n",
      "own : 1.069\n",
      "future : 1.066\n",
      "triumph : 0.988\n",
      "provoking : 0.967\n",
      "scarletti : 0.954\n",
      "war : 0.953\n",
      "Наиболее значимые отрицательные: \n",
      "money : -1.269\n",
      "pseudo : -1.184\n",
      "harlequin : -1.098\n",
      "started : -1.004\n",
      "crappy : -0.985\n",
      "boo : -0.984\n",
      "disney : -0.980\n",
      "bootleg : -0.975\n",
      "happened : -0.974\n",
      "seasoned : -0.951\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.72      0.60      0.65      1240\n",
      "           2       0.48      0.61      0.54       760\n",
      "\n",
      "    accuracy                           0.60      2000\n",
      "   macro avg       0.60      0.61      0.60      2000\n",
      "weighted avg       0.63      0.60      0.61      2000\n",
      "\n",
      "TfidfVectorizer:\n",
      "Символы частоты: all\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наиболее значимые положительные: \n",
      "great : 7.565\n",
      "love : 5.472\n",
      "excellent : 5.114\n",
      "best : 4.416\n",
      "good : 3.913\n",
      "perfect : 3.434\n",
      "well : 3.313\n",
      "easy : 3.068\n",
      "amazing : 2.998\n",
      "wonderful : 2.984\n",
      "Наиболее значимые отрицательные: \n",
      "not : -5.298\n",
      "boring : -5.117\n",
      "waste : -4.704\n",
      "poor : -4.367\n",
      "worst : -4.353\n",
      "disappointed : -4.305\n",
      "bad : -4.287\n",
      "money : -3.812\n",
      "do : -2.948\n",
      "nothing : -2.912\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.87      0.86      0.87      1054\n",
      "           2       0.85      0.86      0.85       946\n",
      "\n",
      "    accuracy                           0.86      2000\n",
      "   macro avg       0.86      0.86      0.86      2000\n",
      "weighted avg       0.86      0.86      0.86      2000\n",
      "\n",
      "Символы частоты: <5%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наиболее значимые положительные: \n",
      "great : 6.640\n",
      "excellent : 5.203\n",
      "love : 4.993\n",
      "best : 4.178\n",
      "perfect : 3.570\n",
      "good : 3.564\n",
      "wonderful : 3.115\n",
      "amazing : 3.037\n",
      "easy : 2.884\n",
      "well : 2.850\n",
      "Наиболее значимые отрицательные: \n",
      "boring : -5.371\n",
      "not : -4.996\n",
      "waste : -4.582\n",
      "poor : -4.551\n",
      "worst : -4.529\n",
      "disappointed : -4.256\n",
      "bad : -3.907\n",
      "money : -3.550\n",
      "disappointing : -3.070\n",
      "do : -2.951\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.84      0.85      1055\n",
      "           2       0.83      0.84      0.84       945\n",
      "\n",
      "    accuracy                           0.84      2000\n",
      "   macro avg       0.84      0.84      0.84      2000\n",
      "weighted avg       0.84      0.84      0.84      2000\n",
      "\n",
      "Символы частоты: 5-20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наиболее значимые положительные: \n",
      "awsome : 1.768\n",
      "medical : 1.714\n",
      "favourite : 1.481\n",
      "enjoying : 1.455\n",
      "ya : 1.445\n",
      "outstanding : 1.431\n",
      "amazing : 1.426\n",
      "ease : 1.424\n",
      "turner : 1.419\n",
      "enjoys : 1.411\n",
      "Наиболее значимые отрицательные: \n",
      "dont : -2.222\n",
      "awful : -2.164\n",
      "wrong : -1.988\n",
      "false : -1.891\n",
      "junk : -1.873\n",
      "annoyed : -1.799\n",
      "missing : -1.754\n",
      "none : -1.709\n",
      "drivel : -1.623\n",
      "ripped : -1.594\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.69      0.71      0.70      1008\n",
      "           2       0.69      0.67      0.68       992\n",
      "\n",
      "    accuracy                           0.69      2000\n",
      "   macro avg       0.69      0.69      0.69      2000\n",
      "weighted avg       0.69      0.69      0.69      2000\n",
      "\n",
      "Символы частоты: >20%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наиболее значимые положительные: \n",
      "heart : 1.601\n",
      "well : 1.341\n",
      "must : 1.142\n",
      "highly : 1.101\n",
      "rock : 1.095\n",
      "excelent : 1.025\n",
      "great : 0.981\n",
      "provoking : 0.960\n",
      "own : 0.957\n",
      "riveting : 0.932\n",
      "Наиболее значимые отрицательные: \n",
      "money : -1.360\n",
      "re : -1.308\n",
      "pseudo : -1.089\n",
      "what : -1.066\n",
      "harlequin : -1.046\n",
      "self : -1.032\n",
      "either : -1.016\n",
      "00 : -1.013\n",
      "there : -1.011\n",
      "half : -0.992\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.60      0.66      1269\n",
      "           2       0.47      0.62      0.54       731\n",
      "\n",
      "    accuracy                           0.61      2000\n",
      "   macro avg       0.60      0.61      0.60      2000\n",
      "weighted avg       0.64      0.61      0.62      2000\n",
      "\n",
      "HashingVectorizer with 100 features:\n",
      "Символы частоты: all\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.66      0.66      0.66      1034\n",
      "           2       0.63      0.63      0.63       966\n",
      "\n",
      "    accuracy                           0.65      2000\n",
      "   macro avg       0.65      0.65      0.65      2000\n",
      "weighted avg       0.65      0.65      0.65      2000\n",
      "\n",
      "HashingVectorizer with 200 features:\n",
      "Символы частоты: all\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.71      0.70      0.70      1045\n",
      "           2       0.67      0.68      0.68       955\n",
      "\n",
      "    accuracy                           0.69      2000\n",
      "   macro avg       0.69      0.69      0.69      2000\n",
      "weighted avg       0.69      0.69      0.69      2000\n",
      "\n",
      "HashingVectorizer with 500 features:\n",
      "Символы частоты: all\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.77      0.77      0.77      1031\n",
      "           2       0.76      0.75      0.75       969\n",
      "\n",
      "    accuracy                           0.76      2000\n",
      "   macro avg       0.76      0.76      0.76      2000\n",
      "weighted avg       0.76      0.76      0.76      2000\n",
      "\n",
      "HashingVectorizer with 1000 features:\n",
      "Символы частоты: all\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.80      0.79      0.80      1049\n",
      "           2       0.78      0.79      0.78       951\n",
      "\n",
      "    accuracy                           0.79      2000\n",
      "   macro avg       0.79      0.79      0.79      2000\n",
      "weighted avg       0.79      0.79      0.79      2000\n",
      "\n",
      "HashingVectorizer with 10000 features:\n",
      "Символы частоты: all\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.84      0.85      0.84      1027\n",
      "           2       0.84      0.83      0.83       973\n",
      "\n",
      "    accuracy                           0.84      2000\n",
      "   macro avg       0.84      0.84      0.84      2000\n",
      "weighted avg       0.84      0.84      0.84      2000\n",
      "\n",
      "HashingVectorizer with 100000 features:\n",
      "Символы частоты: all\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.85      0.85      1045\n",
      "           2       0.84      0.84      0.84       955\n",
      "\n",
      "    accuracy                           0.85      2000\n",
      "   macro avg       0.85      0.85      0.85      2000\n",
      "weighted avg       0.85      0.85      0.85      2000\n",
      "\n",
      "HashingVectorizer with 1000000 features:\n",
      "Символы частоты: all\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.86      0.85      0.86      1049\n",
      "           2       0.84      0.85      0.84       951\n",
      "\n",
      "    accuracy                           0.85      2000\n",
      "   macro avg       0.85      0.85      0.85      2000\n",
      "weighted avg       0.85      0.85      0.85      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
    "\n",
    "\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "def filtered_text(df_, freq_type):\n",
    "    return [ ' '.join(t for t in tt if t in freq_dicts[freq_type]) for tt in df_['text_tokens'] ]\n",
    "    \n",
    "def fit_and_test(freq_type, vec, clf=None):\n",
    "    print('Символы частоты: ' + freq_type)\n",
    "    x_train = filtered_text(df_train, freq_type)\n",
    "    y_train = df_train['category']\n",
    "    x_test = filtered_text(df_test, freq_type)\n",
    "    y_test = df_test['category']\n",
    "    \n",
    "    if clf == None:\n",
    "        clf = LogisticRegression(random_state=42)\n",
    "    \n",
    "    bow = vec.fit_transform(x_train)\n",
    "    \n",
    "    clf.fit(bow, y_train)\n",
    "    if hasattr(vec, 'get_feature_names'):\n",
    "        feature_names = vec.get_feature_names()\n",
    "        coefs_with_importances = sorted(zip(clf.coef_[0], feature_names))\n",
    "        n_important = 10;\n",
    "        print(\"Наиболее значимые положительные: \")\n",
    "        for t in reversed(coefs_with_importances[-n_important:]):\n",
    "            print(f\"{t[1]} : {t[0]:.3f}\")\n",
    "        print(\"Наиболее значимые отрицательные: \")\n",
    "        for t in coefs_with_importances[:n_important]:\n",
    "            print(f\"{t[1]} : {t[0]:.3f}\")\n",
    "\n",
    "    pred = clf.predict(vec.transform(x_test))\n",
    "    print(classification_report(pred, y_test))\n",
    "    \n",
    "    \n",
    "\n",
    "print('CountVectorizer:')\n",
    "for freq_type in freq_dicts:\n",
    "    fit_and_test(freq_type, CountVectorizer(ngram_range=(1, 1)))\n",
    "    \n",
    "print('TfidfVectorizer:')\n",
    "for freq_type in freq_dicts:\n",
    "    fit_and_test(freq_type, TfidfVectorizer(ngram_range=(1, 1)))\n",
    "    \n",
    "for n_features in [100, 200, 500, 1000, 10000, 100000, 1000000]:\n",
    "    print(f'HashingVectorizer with {n_features} features:')\n",
    "    fit_and_test('all', HashingVectorizer(analyzer='word', n_features=n_features))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a54459",
   "metadata": {},
   "source": [
    "### Выводы по заданию 1:\n",
    "Наилучший результат получился с использованием наиболее популярных токенов, как с CountVectorizer, так и с TfidfVectorizer. Вероятно, наименее популярные токены хорошо выделяют отдельные документы, но не категорию. Самый лучший результат получался по полному набору токенов\n",
    "\n",
    "### Выводы по заданию 2:\n",
    "Фичи с наибольшей значимостью вполне подходят к каждой из категорий, особенно для полного и наиболее популярного наборов\n",
    "\n",
    "### Выводы по заданию 3:\n",
    "1. (кроме полносвязной сетки) - лучше всего отработал TfIdfVectorizer. HashingVectorizer приблизился к этому результату на больших размерах > 10000\n",
    "2. Близкие к максимальным метрики получаются у HashingVectorizer, начиная с размера 10000, но продолжают слегка улучшаться вплоть до 1000000."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f8ad0d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
